# Awesome Golang.ai

Golang AI applications have incredible potential. With unique features like inexplicable speed, easy debugging, concurrency, and excellent libraries for ML, deep learning, and reinforcement learning.

## Benchmark

### English

- [ARC-AGI](https://github.com/fchollet/ARC-AGI): The Abstraction and Reasoning Corpus.
- [ARC-Challenge](https://github.com/allenai/ARC-Solvers?tab=readme-ov-file): AI2 Reasoning Challenge (ARC) Set.
- [BBH](https://github.com/suzgunmirac/BIG-Bench-Hard): Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.
- [BIG-bench](https://github.com/google/BIG-bench): Beyond the Imitation Game collaborative benchmark for measuring and extrapolating the capabilities of language models.
- [GPQA](https://github.com/idavidrein/gpqa): GPQA: A Graduate-Level Google-Proof Q&A Benchmark.
- [HelloSwag](https://github.com/rowanz/hellaswag): HellaSwag: Can a Machine _Really_ Finish Your Sentence?
- [IFEval](https://huggingface.co/datasets/google/IFEval): IFEval is designed to systematically evaluate the instruction-following capabilities of large language models by incorporating 25 verifiable instruction types (e.g., format constraints, keyword inclusion) and applying dual strict-loose metrics for automated, objective assessment of model compliance.
- [LiveBench](https://github.com/LiveBench/LiveBench): A Challenging, Contamination-Free LLM Benchmark.
- [MMLU](https://github.com/hendrycks/test): Measuring Massive Multitask Language Understanding ICLR 2021.
- [MMLU-CF](https://github.com/microsoft/MMLU-CF): A Contamination-free Multi-task Language Understanding Benchmark.
- [MMLU-Pro](https://github.com/TIGER-AI-Lab/MMLU-Pro): [NeurIPS 2024] A More Robust and Challenging Multi-Task Language Understanding Benchmark.
- [MTEB](https://github.com/embeddings-benchmark/mteb): Massive Text Embedding Benchmark.
- [PIQA](https://github.com/ybisk/ybisk.github.io/tree/master/piqa): PIQA is a dataset for commonsense reasoning, and was created to investigate the physical knowledge of existing models in NLP.
- [WinoGrande](https://github.com/allenai/winogrande): An Adversarial Winograd Schema Challenge at Scale.

### Chinese

- [C-Eval](https://github.com/hkust-nlp/ceval): [NeurIPS 2023] A Chinese evaluation suite for foundation models.
- [CMMLU](https://github.com/haonan-li/CMMLU): Measuring massive multitask language understanding in Chinese.
- [C-SimpleQA](https://github.com/OpenStellarTeam/ChineseSimpleQA): A Chinese Factuality Evaluation for Large Language Models.

### Math

- [AIME](https://github.com/eth-sri/matharena): Evaluation of LLMs on latest math competitions.
- [grade-school-math](https://github.com/openai/grade-school-math): The GSM8K dataset contains 8.5K grade school math word problems designed to evaluate multi-step reasoning capabilities in language models, revealing that even large transformers struggle with these conceptually simple yet procedurally complex tasks.
- [MATH](https://github.com/hendrycks/math): The MATH Dataset for NeurIPS 2021, is a benchmark for evaluating mathematical problem-solving capabilities, offering dataset loaders, evaluation code, and pre-training data.
- [MathVista](https://github.com/lupantech/MathVista): MathVista: data, code, and evaluation for Mathematical Reasoning in Visual Contexts.
- [Omni-MATH](https://github.com/KbsdJames/Omni-MATH): Omni-MATH is a comprehensive and challenging benchmark specifically designed to assess LLMs' mathematical reasoning at the Olympiad level.
- [TAU-bench](https://github.com/sierra-research/tau-bench): TauBench is an open-source benchmark suite designed to evaluate the performance of large language models (LLMs) on complex reasoning tasks across multiple domains.

### Code

- [AIDER](https://github.com/Aider-AI/aider): The leaderboards page of aider presents a performance comparison of various LLMs in programming-related tasks, such as code writing and editing.
- [BFCL](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html): BFCL aims to provide a thorough study of the function-calling capability of different LLMs.
- [BigCodeBench](https://github.com/bigcode-project/bigcodebench/): [ICLR'25] BigCodeBench: Benchmarking Code Generation Towards AGI.
- [Code4Bench](https://github.com/code4bench/Code4Bench): A Mutildimensional Benchmark of Codeforces Data for Different Program Analysis Techniques.
- [CRUXEval](https://github.com/facebookresearch/cruxeval): Code Reasoning, Understanding, and Execution Evaluation.
- [HumanEval](https://github.com/openai/human-eval): Code for the paper "Evaluating Large Language Models Trained on Code".
- [LiveCodeBench](https://github.com/LiveCodeBench/LiveCodeBench): Holistic and Contamination Free Evaluation of Large Language Models for Code.
- [MBPP](https://github.com/google-research/google-research/tree/master/mbpp): The benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on.
- [MultiPL-E](https://github.com/nuprl/MultiPL-E): A multi-programming language benchmark for LLMs.
- [SWE-bench](https://github.com/SWE-bench/SWE-bench): SWE-bench is a benchmark suite designed to evaluate the capabilities of large language models (LLMs) in solving real-world software engineering tasks, focusing on actual software bug-fixing challenges extracted from open-source projects.

### Tool Use

- [BFCL](https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard): Training and Evaluating LLMs for Function Calls (Tool Calls).
- [T-Eval](https://github.com/open-compass/T-Eval): [ACL2024] T-Eval: Evaluating Tool Utilization Capability of Large Language Models Step by Step.
- [WildBench](https://github.com/allenai/WildBench): Benchmarking LLMs with Challenging Tasks from Real Users.

### Open ended

- [Arena-Hard](https://github.com/lmarena/arena-hard-auto): Arena-Hard-Auto: An automatic LLM benchmark.

### Safety

### False refusal

- [Xstest](https://github.com/paul-rottger/xstest): Röttger et al. (NAACL 2024): "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models".

### Multi-modal

- [DPG-Bench](https://github.com/TencentQQGYLab/ELLA): The DPG benchmark tests a model’s ability to follow complex image generation prompts.
- [geneval](https://github.com/djghosh13/geneval): GenEval: An object-focused framework for evaluating text-to-image alignment.
- [LongVideoBench](https://github.com/longvideobench/LongVideoBench): [Neurips 24' D&B] Official Dataloader and Evaluation Scripts for LongVideoBench.
- [MLVU](https://github.com/JUNJIE99/MLVU): Multi-task Long Video Understanding Benchmark.
- [perception_test](https://github.com/google-deepmind/perception_test): A Diagnostic Benchmark for Multimodal Video Models is a multimodal benchmark designed to comprehensively evaluate the perception and reasoning skills of multimodal video models.
- [TempCompass](https://github.com/llyx97/TempCompass): A benchmark to evaluate the temporal perception ability of Video LLMs.
- [VBench](https://github.com/Vchitect/VBench): VBench is an open-source project aiming to build a comprehensive evaluation benchmark for video generation models.
- [Video-MME](https://github.com/BradyFU/Video-MME): [CVPR 2025] Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis.

## [Model Context Protocol](https://modelcontextprotocol.io/introduction)

- [mcp-go](https://github.com/mark3labs/mcp-go): A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.
- [mcp-golang](https://github.com/metoro-io/mcp-golang): Write Model Context Protocol servers in few lines of go code. 
  
## Large Language Model

### ChatGPT Apps

- [feishu-openai](https://github.com/ConnectAI-E/feishu-openai):Feishu (Lark) integrated with (GPT-4 + GPT-4V + DALL·E-3 + Whisper) delivers an extraordinary work experience.
- [chatgpt-telegram](https://github.com/m1guelpf/chatgpt-telegram): Run your own GPTChat Telegram bot, with a single command.

### SDKs

- [openai-go](https://github.com/openai/openai-go): The official Go library for the OpenAI API.
- [generative-ai-go](https://github.com/google/generative-ai-go): Go SDK for Google Generative AI.
- [anthropic-sdk-go](https://github.com/anthropics/anthropic-sdk-go): Access to Anthropic's safety-first language model APIs via Go.

### DevTools

- [ollama](https://github.com/ollama/ollama): Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.
- [go-attention](https://github.com/takara-ai/go-attention): A full attention mechanism and transformer in pure go.
- [langchaingo](https://github.com/tmc/langchaingo): LangChain for Go, the easiest way to write LLM-based programs in Go.
- [gpt4all-bindings](https://github.com/nomic-ai/gpt4all/tree/41c9013fa46a194b3e4fee6ced1b9d1b65e177ac/gpt4all-bindings/golang): GPT4All Language Bindings provide cross-language interfaces to easily integrate and interact with GPT4All's local LLMs, simplifying model loading and inference for developers.
- [go-openai](https://github.com/sashabaranov/go-openai): OpenAI ChatGPT, GPT-3, GPT-4, DALL·E, Whisper API wrapper for Go.
- [llama.go](https://github.com/gotzmann/llama.go): llama.go is like llama.cpp in pure Golang.
- [eino](https://github.com/cloudwego/eino): The ultimate LLM/AI application development framework in Golang.
- [fabric](https://github.com/danielmiessler/fabric): fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.
- [genkit](https://github.com/firebase/genkit): An open source framework for building AI-powered apps with familiar code-centric patterns. Genkit makes it easy to develop, integrate, and test AI features with observability and evaluations. Genkit works with various models and platforms.

### Retrieval-Augmented Generation


### Vector Database

- [milvus](https://github.com/milvus-io/milvus): Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search.
- [weaviate](https://github.com/weaviate/weaviate): Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database​.
- [tidb](https://github.com/pingcap/tidb): TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.

### Pipeline and Data Version

- [pachyderm](https://github.com/pachyderm/pachyderm): Data-Centric Pipelines and Data Versioning.

## General Machine Learning libraries

- [goml](https://github.com/cdipaolo/goml)：On-line Machine Learning in Go (and so much more).
- [golearn](https://github.com/sjwhitworth/golearn): simple and customizable batteries included ML library in Go.
- [gonum](https://github.com/gonum/gonum)：Gonum is a set of numeric libraries for the Go programming language. It contains libraries for matrices, statistics, optimization, and more.
- [gorgonia](https://github.com/gorgonia/gorgonia): Gorgonia is a library that helps facilitate machine learning in Go.
- [spago](https://github.com/nlpodyssey/spago): Self-contained Machine Learning and Natural Language Processing library in Go.
- [goro](https://github.com/aunum/goro): A High-level Machine Learning Library for Go.
- [goga](https://github.com/tomcraven/goga): Golang Genetic Algorithm.
- [hep](https://github.com/go-hep/hep): hep is the mono repository holding all of go-hep.org/x/hep packages and tools.
- [hector](https://github.com/xlvector/hector): Golang machine learning lib.
- [sklearn](https://github.com/pa-m/sklearn): bits of sklearn ported to Go.

## Neural Networks

- [gobrain](https://github.com/goml/gobrain): Neural Networks written in go.
- [go-neural](https://github.com/NOX73/go-neural): Neural network implementation on golang.
- [go-deep](https://github.com/patrikeh/go-deep): Artificial Neural Network.
- [olivia](https://github.com/olivia-ai/olivia): Your new best friend powered by an artificial neural network.
- [gomid](https://github.com/surenderthakran/gomind): A simplistic Neural Network Library in Go.
- [neurgo](https://github.com/tleyden/neurgo): Neural Network toolkit in Go.
- [gonn](https://github.com/fxsjy/gonn): GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN.
- [gosom](https://github.com/milosgajdos/gosom): Self-organizing maps in Go.
- [go-perceptron-go](https://github.com/made2591/go-perceptron-go): A single / multi layer / recurrent neural network written in Golang.

## Linear Algebra

- [gosl](https://github.com/cpmech/gosl): Linear algebra, eigenvalues, FFT, Bessel, elliptic, orthogonal polys, geometry, NURBS, numerical quadrature, 3D transfinite interpolation, random numbers, Mersenne twister, probability distributions, optimisation, differential equations.
- [sparse](https://github.com/james-bowman/sparse): Sparse matrix formats for linear algebra supporting scientific and machine learning applications.

## Probability Distributions

- [godist](https://github.com/e-dard/godist): Probability distributions and associated methods in Go.

## Decision Trees

- [CloudForest](https://github.com/ryanbressler/CloudForest)
## Regression

- [regression](https://github.com/sajari/regression): Multivariable regression library in Go.
- [ridge](https://github.com/promacanthus/ridge): Ridge regression in Go.

## Bayesian Classifiers

- [bayesian](https://github.com/jbrukh/bayesian): Naive Bayesian Classification for Golang.
- [multibayes](https://github.com/lytics/multibayes): Multiclass Naive Bayesian Classification.

## Recommendation Engines

- [regommend](https://github.com/muesli/regommend): Recommendation engine for Go.
- [gorse](https://github.com/zhenghaoz/gorse): Go Recommender System Engine.
- [too](https://github.com/FurqanSoftware/too): Simple recommendation engine implementation built on top of Redis.

## Evolutionary Algorithms

- [eaopt](https://github.com/MaxHalford/eaopt): Evolutionary optimization library for Go (genetic algorithm, partical swarm optimization, differential evolution).
- [evo](https://github.com/cbarrick/evo): Evolutionary Algorithms in Go.

## Graph

- [gogl](https://github.com/sdboyer/gogl): A graph library in Go.

## Cluster

- [gokmeans](https://github.com/mash/gokmeans): K-means algorithm implemented in Go (golang).
- [kmeans](https://github.com/muesli/kmeans): k-means clustering algorithm implementation written in Go.

## Anomaly Detection

- [morgoth](https://github.com/nathanielc/morgoth): Metric anomaly detection.
- [anomalyzer](https://github.com/lytics/anomalyzer): Probabilistic anomaly detection for time series data.
- [goanomaly](https://github.com/sec51/goanomaly): Golang library for anomaly detection. Uses the Gaussian distribution and the probability density formula.

## DataFrames

- [gota](https://github.com/go-gota/gota): Gota: DataFrames and data wrangling in Go.
- [dataframe-go](https://github.com/rocketlaunchr/dataframe-go): DataFrames for Go: For statistics, machine-learning, and data manipulation/exploration.
- [qframe](https://github.com/tobgu/qframe): Immutable data frame for Go.

## Explaining Model

- [lime](https://github.com/marcotcr/lime): Lime: Explaining the predictions of any machine learning classifier.

# Books

- [Machine Learning With go](https://github.com/promacanthus/awesome-golang-ai/blob/main/books/Machine%20Learning%20with%20Go.pdf)
- [Machine-Learning-With-Go](https://github.com/promacanthus/Machine-Learning-With-Go): example code.
- [机器学习：Go语言实现](https://github.com/promacanthus/awesome-golang-ai/blob/main/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20Go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0.pdf)
- [GO语言机器学习实战](https://book.douban.com/subject/35037170/)

# Basic Knowledge

## Reinforcement Learning

- [Hands-on Reinforcement Learning](https://hrl.boyuai.com/)

# Datasets

- [LendingClub]()

# Star History

<!-- Copy-paste in your Readme.md file -->

<a href="https://next.ossinsight.io/widgets/official/analyze-repo-stars-history?repo_id=444070344" target="_blank" style="display: block" align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/analyze-repo-stars-history/thumbnail.png?repo_id=444070344&image_size=auto&color_scheme=dark" width="721" height="auto">
    <img alt="Star History of promacanthus/awesome-golang-ai" src="https://next.ossinsight.io/widgets/official/analyze-repo-stars-history/thumbnail.png?repo_id=444070344&image_size=auto&color_scheme=light" width="721" height="auto">
  </picture>
</a>

<!-- Made with [OSS Insight](https://ossinsight.io/) -->

# Star Geographical Distribution

<!-- Copy-paste in your Readme.md file -->

<a href="https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?repo_id=444070344&activity=stars" target="_blank" style="display: block" align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?repo_id=444070344&activity=stars&image_size=auto&color_scheme=dark" width="721" height="auto">
    <img alt="Star Geographical Distribution of promacanthus/awesome-golang-ai" src="https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?repo_id=444070344&activity=stars&image_size=auto&color_scheme=light" width="721" height="auto">
  </picture>
</a>

<!-- Made with [OSS Insight](https://ossinsight.io/) -->
